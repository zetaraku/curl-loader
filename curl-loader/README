    curl-loader
    Robert Iakobashvili, Ashdod, Israel, coroberti@gmail.com
    Michael Moser, Modiin, Israel, moser.michael@gmail.com

ABOUT:
    Provides application load using libcurl/openssl stacks, simulating behaviour
of thousands and tens of thousands clients, each with its own source IP-address.
    This version simulates HTTP/HTTPS and FTP/FTPS (experimental) clients. 
Activities of each virtual client are logged to file: resolving, connection
establishment, sending of requests, receiving responses, headers and data 
received/sent, errors from network, TLS/SSL and application (HTTP, FTP) levels. 
The tool can be easily extended to generate telnet, tftp, ldap, etc other 
application load, supported by the great libcurl library.
    Virtual clients are grouped to so-called batches of clients, performing
the same sort of activities. Configurable activities for the simulated clients are:
- authentication login;
- user activity simulation by fetching several urls and timeouts in between;
- logoff.



THANKS:
Thanks to the creators and maintainers of libcurl (Daniel Stenberg) for the HTTP 1.1,
FTP, telnet, ldap, etc client stacks, of openssl for the TLS/SSL stack, of libevent 
(Niels Provos) for the demultiplexing framework, of iprouted2, netlink and linux TCP/IP
kernel (Alexey Kuznetsov and others).
More thanks specific to the tool are in the THANKS file.




LICENSE:
Actually it is GPL2 due to the code from iprouted2. However, if somebody
fills uncomfortable with this license, we can consider BSD-license, and/or 
make it configurable.


TERMINOLOGY:
--- What is the batch?
Batch is a group of clients with the same characteristics and 
loading behavior. Configuration file has one or more batches.
--- What means UAS?
UAS - user activity simulation - fetching url, sleeping, another url -sleeping
cycles, simulating actual user activity.



SUCCESSFULLY USED:

1. To simulate HTTP/S load of thousands of clients against authentication 
   gateway for testing of the gateway performance in various scenarios.

    curl-loader supplied HTTP/S client load against Apache web-server with the 
    gateway in the middle, where the gateway made a browser hijacking and HTTP- 
    redirection of the curl-clients to the HTTPS url at the gateway's own 
    web-server. HTTPS page of the web-server provided a POST form to the user
    with username and password for the client/user authentication against
    an external AAA (RADIUS) server. If the authentication was OK, user (a libcurl
    virtual client object) was allowed to enter the Internet and to perform some
    sort of simulated by curl-loader network activity, namely, fetching urls and 
    sleeping in between them. After enjoying Internet, user was coming to logoff.
    
2. To test web-server pages, authenticating tens and hundred thousand of
    clients, where each client comes to a HTTPS url using GET method and is
    redirected by the web-server to another url, providing authentication POST 
    form with username and password. After successful authentication of a client
    the web-server was setting to the client server-cookies. Client activities were 
    further simulated by fetching urls and sleeping in between. Clients were 
    doing logoff using GET-method to the web-server logoff-url, where the cookies
    were used by the web-server to verify clients identity.

3. To generate Gbps traffic from thousands of TCP/HTTP clients and to test the 
    impact of thousands of firewalling and NAT iptables/ipset rules and 
    hundreds of the rules being added/deleted each second at performance of a 
    gateway device.

    curl-loader provided client load against Apache web-server fetching a 
    url with a gigabyte file, thus, creating a permanent heavy-load 
    traffic, containing thousands of tcp-streams at the gateway in the middle.


MAY BE USED:
1. To create testing performance load for various HTTP/HTTPS/FTP/FTPS/LDAP, 
    etc devices, where libcurl supports various variants and flavors of the protocols;
2. For testing of HTTP/HTTPS, FTP/FTPS based applications, application servers;
3. For etc, etc, etc applications.


LOAD STATUS GUI:
curl-loader outputs to the console loading status and statistics as the "standing" 
ouput, where the upper part is for the latest interval and below is the average 
numbers since load start. The example is below:

=====================================================
Last interval stats (interval:3 sec, clients:10, CAPS:3):
 Operations:    Success         Failed
 LOGIN:         4               1
 UAS-0:         3               0
 LOGOFF:        2               0
HTTP/FTP-Req:10,2xx:5,3xx:4,4xx:0,5xx:1,Err:0,Delay:20,Delay-2xx:12,Thr-in:12015(b/s),Thr-out:35511(b/s)
HTTPS/FTPS-Req:0,2xx:0,3xx:0,4xx:0,5xx:0,Err:0,Delay:0,Delay-2xx:0,Thr-in:0(b/s),Thr-out:0(b/s)
-----------------------------------------------------
Summary stats since load start (load runs:24 secs, CAPS-average:4):
 Operations:    Success         Failed
 LOGIN:         0               32
 UAS-0:         0               0
 LOGOFF:        0               0
HTTP/FTP-Req:95,2xx:47,3xx:48,4xx:0,5xx:3,Err:1,Delay:31,Delay-2xx:15,Thr-in:113921(b/s),Thr-out:330215(b/s)
HTTPS/FTPS-Req:0,2xx:0,3xx:0,4xx:0,5xx:0,Err:0,Delay:0,Delay-2xx:0,Thr-in:0(b/s),Thr-out:0(b/s)
=====================================================

A copy of the output is also safed in the file <batch-name>.txt
The detailed explanations about the file, collected statistics and 
troubleshooting are in HOWTOS-STATISTICS.



LOGIN/LOGOFF SUPPORT:
Login and logoff operations curl-loader preforms using HTTP methods:
- GET+POST (server response to GET provides a post-form to be 
   filled and posted by POST);
- POST only;
- GET only.



AUTHENTICATION SUPPORT:
The loader supports HTTP Web Authentication and Proxy Authentication.
Authentication methods supported are Basic, Digest (RFC2617) and NTLM.
When responded 401 or 407, libcurl will choose the most safe method
from those, supported by the server.
To support GSS Web-Authentication, add in Makefile building of libcurl
against appropriate GSS library, see libcurl pages for detailed instructions.



COOKIES SUPPORT:
HTTP cookies are enabled in curl-loader by default.



FTP/FTPS LOAD (experimental):
To generate FTP/FTPS load, please, use UAS section and pass user credentials
via ftp-url according to the RFC 1738 like:
ftp://username:password@hostname:port/etc-str
Look at conf-examples/ftp.conf



PERFORMANCE ISSUES:
There is no more 1000 virtual clients per batch limit due to select FD_SETSIZE,
so you can try 2000 and may be more number of clients from the single thread
(select). Please, care about available sockets and limits. System call select () 
does not scale well with a big number of sockets, therefore, you can try a 
script, which runs several instances of curl_loader, each with 1000-2000 
clients.

Running several batches with threads (option -t), each with 1000-2000 clients is 
another valid option, however, may be less stable - try it.

A future release will incorporate libcurl HYPER API to support tens of thousand 
of virtual clients from a single curl-loader process, using curl_multi_socket() 
approach and epoll API support by libevent as in
http://curl.haxx.se/lxr/source/hiper/hipev.c

Read also HOWTOS-BIG-LOAD.



MODES:
One of the modes is called "storming" (-m1 command line), where all clients 
of a batch are starting together. They are expected to finish their job within
a certain timeout. After the timeout they are either completed fetching url, 
or are cutted and disconnected and a new cycle begins. Storming mode is better 
to use, when login operation is a single one and not in cycles, or when the 
tool is used just as a traffic generator. 

Another mode is a so-called "smooth" (the default mode or -m2 command line), 
where each client spends as much time as wishes and starts another url or 
another cycle only after completing the previous url. When a client loading is
terminated due to some reason, e.g. connection timeout, the default behavior
is to schedule loading for this client at the next cycle. If -e option is passed to
command line, the client will not be re-scheduled any more, which is usefull
to get indication of errors by monitoring drop in number of active clients. Look
in logfile for errors, and when connection timeout error appears, adjust the
connection timeout using -c command line option. Note, that the smooth mode
is suitable for login-logoff cycles of load.

A combination of the both modes (two separate instances of the program)
can provide somehow realistic behavior with some "smooth" load plus
"storming" bursts of requests.

Hyper-mode (option -m3) is currently "under construction".



GRADUAL INCREASE OF LOAD AT START:
Use configuration tag CLIENTS_INITIAL_INC to specify the number of 
loading clients to be added each second till the total clients number reaches 
the number specified by CLIENTS_NUM tag.



CAPS CONSIDERATIONS:
When number of clients is defined by CLIENTS_NUM tag, the number of
CAPS (call attempts per seconds) is resulting from the clients number and 
load duration for each cycle, comprising from:
- login time with possible redirections and sleeping after login interval;
- uas time for each url with possible redirections, intervals betwee urls and 
  after uas interval;
- logoff time with possible redirections and sleeping after logoff interval;

The actions and time intervals are configurable in batch file, whereas
url retrival time is server and network dependent and not always easy 
to predict. The result is that number of clients/requests is a known parameter,
and number of CAPS is something to be estimated from the time of test and
number of requests.
Smooth mode presents at the LOAD STATUS GUI output calculated current 
and average CAPS numbers.



OS SUPPORT:
Supposed to work on linux 2.4 and 2.6 kernels.



BUILDING:
In most cases just run make and relax.

For some linux distributions, however,  matters should be fine tuned in 
Makefile (libidn issues, etc). 

Building requirements include:
1. openssl binaries;
2. openssl development package with include files (on debian package libssl-dev);
3. ncurses development package to run 'make menuconfig' with dialog GUI.

Adjust Makefile variables to point to the openssl headers and 
libraries. If you want to specify an openssl development directory with 
include files (e.g. crypto.h), export environment variable OPENSSLDIR with 
the value of that directory.

Build curl-loader by e.g.:
%tar zxfv curl-loader-<version>.tar.gz
%cd curl-loader-<version>
%make

Another known issue is linidn.so, which means, that some linux distributions 
do have some libidn.so.11, but not libidn.so. Resolve it by creating a softlink.

Tarball of curl is included to the current release. When libcurl or curl-loader 
have building issues, correct them in the Makefile. 

By default, we are building both libcurl and curl-loader without optimization and with
debugging -g option. To build with optimization and without debugging, please, run:
%make cleanall 
%make optimize=1 debug=0
If still any building issues, please, fill you free to contact us for assistance.



COMMAND-LINE OPTIONS:
Usage: run as a root user:
#./curl-loader -f <configuration filename> [other options]

Possible options are:
-c[onnection establishment timeout, seconds]
-e[rror drop client (smooth mode). Client on error doesn't attempt loading any mode]
-h[elp]
-i[ntermediate (snapshot) statistics time interval (default 3 sec)]
-f[ilename of configuration to run (batches of clients)]
-l[ogfile max size in MB (default 1024). On the size reached, file pointer rewinded]
-m[ode of loading, 1 - storming, 2 - smooth (default)]
-o[utput to stdout bodies of downloaded files - attn!- bulky]
-r[euse connections disabled. Close connections and re-open them. Try with and without]
-s[tderr printout of client messages instead of to logfile - attn!- bulky]
-t[hreads enable - enables threads, each runs a batch of clients]
-v[erbose output to the logfiles; includes info about headers sent/received]
-u[rl logging - logs url names to logfile, when -v verbose option is used]

For the rare cases, when several batches are specified in the same config file,
note, please, that curl-loader without -t this option runs only the first batch of 
clients specified.
Thus, running several client batches without threads requires some script with
several curl-loader processes.

Connection Reuse Disable Option (-r):
The default behavior of curl-loader after HTTP response is to re-use the 
tcp-connection for the next request. If you are specifying -r command-line 
option, the TCP connection will be closed and re-opened for the next request. 
Whether it is appropriate for you to work with -r option or without, it  depends
on your server support of Keep-Alive and the purpose of your testing.
Try with and without -r and see, what you get.

Connection reuse (just the default, without -r option) has advantages due to the 
decreased consumption of opened descriptors (sockets) and ports.




CONFIGURATION FILE:

NEW! DIALOG GUI TO GUIDE THROUGH LOADING CONFIGURATION!

To run your load, you need to create your configuration file to be passed to
curl-loader by the -f commmand line option, e.g.
#curl-loader -f ./conf-user/user_batch.conf
For more examples, please, look at the files in "conf-examples" directory.
You may copy an example file and edit it by using HOWTOS-CONFIG-FILE guidlines.

You may start with running by "make menuconfig" configuration GUI on your system, 
which requires ncurses development package on your system.
The dialog window will guide you and create your configuration file in 
conf-user directory. The current limitation of the menu-guided configuration, is
that enables to create a single UAS URL.
If you need more that a single UAS url, copy your batch file from the conf-user
directory  to some other place and  edit it by adding as much url tag series 
(below) as you need, but don't forget to update UAS_URLS_NUM accordingly.
The UAS url tag series:
UAS_URL=
UAS_URL_USERNAME=
UAS_URL_PASSWORD=
UAS_URL_MAX_TIME =
UAS_URL_INTERLEAVE_TIME =

For more details you may look at HOWTOS-CONFIG-FILE



LINUX ENVIRONMENT: ATTENTION !!! IMPORTANT !!!
Running hundreds and thousands of clients, please do not forget:
    - to increase limit of descriptors (sockets) by running e.g. 
      #ulimit -n 10000;
    - optionally, to set reuse of sockets in time-wait state: by setting 
      #echo 1 > /proc/sys/net/ipv4/tcp_tw_recycle and/or  
      #echo 1 > /proc/sys/net/ipv4/tcp_tw_reuse;
In some cases you may need to increase the system limits for open
descriptors (sockets).



DETAILED LOGFILE 
<Batch-Name>.log:

The semantics of logfile output, using command line options -v (verbous) and -u 
(url print):
"Cycle number", "Client number (ip-address)" - some information string, e.g.:

4 39 (192.168.0.39)  :== Info:   Trying 10.30.6.42... : eff-url: http://10.30.6.42:8888/server/Admin/ServiceList.do, url:

Which meas: cycle: 4, client number 39 with ipv4 address (192.168.0.39), 
status of the message is Info, eff-url - is the url, used right now, "url:" is 
empty, which means, that it is the same as effective.

Effective url may be a result of redirection and, thus, "url:" 
(target url, specified in batch configuration file) will be printed as well.




STATISTICS:
See HOWTOS-STATISTICS


HOWTOS-BIG-LOAD
The file contains some useful tips.



LIMITATIONS:
See the TODO file for some of them.
