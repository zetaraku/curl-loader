    curl-loader, version 0.19

    Robert Iakobashvili, Ashdod, Israel, coroberti@gmail.com
    Michael Moser, Modiin, Israel, moser.michael@gmail.com

ABOUT:
    Provides application load using libcurl/openssl stacks, simulating behaviour
of thousands and tens of thousands clients, each with its own source IP-address.
    This version simulates HTTP/HTTPS and FTP/FTPS clients. Activities of each 
virtual client are logged to file: resolving, connection establishment, request 
headers sent, response headers received, data received/sent, errors from TCP, 
SSL and application (HTTP, FTP) levels. The tool can be easily extended to 
support telnet, tftp, ldap, etc other application protocols, supported by the 
great libcurl library.
    Virtual clients are grouped to the so-called batches of clients, performing
the same sort of activities. Configurable activities of the simulated clients are:
- authentication login;
- user activity simulation by fetching several urls and timeouts in between;
- logoff.


SUCCESSFULLY USED:

1. To simulate HTTP/HTTPS load of thousands of clients against an authentication 
    gateway for testing of the gateway performance in various scenarios.

     curl-loader supplied  client load against Apache web-server with the gateway 
    in the middle, where the gateway performed browser hijacking and HTTP- 
    redirection of the curl-clients to the HTTPS url at the gateway own 
    web-server. HTTPS page of the web-server responded with a POST form to be 
    filled with username and password for the client/user authentication against
    an external AAA (RADIUS) server. If the authentication was OK, user (a libcurl
    virtual client object) was allowed to enter the Internet and to perform some
    sort of simulated by curl-loader network activity, namely, fetching urls and 
    sleeping in between them.   
    
2. To test web-server pages, authenticating tens and hundred thousand of
    clients, where each clients comes to HTTPS url using GET and is redirected
    to another url, providing authentication POST form. After client successful 
    authentication the web-server sets cookies to the client. Client activities 
    are further simulated by fetching urls and sleeping in between. Clients are 
    doing logoff via GET to the logoff-url (using cookies).

3. To generate Gbps traffic from thousands of TCP/HTTP clients and to test the 
    impact of thousands of firewalling and NAT iptables/ipset rules and 
    hundreds of the rules being added/deleted each second at performance of a 
    gateway device.

    curl-loader provided client load against Apache web-server fetching a 
    url with a gigabyte file, thus, creating a permanent heavy-load 
    traffic, containing thousand of tcp-streams at the gateway in the middle.

MAY BE USED:
1. To create testing load for various HTTP/HTTPS/FTP/FTPS/LDAP, etc devices, 
    where libcurl supports various variants and flavors of the protocols;
2. For testing of HTTP/HTTPS, FTP/FTPS based applications, application servers;
2. For etc, etc, etc applications.

OS SUPPORT:
Currently linux due to actually unlimited number of secondary ip-addresses,
that can be arranged at a network interface to bind each individual client
to an IP-address.
Supposed to work on linux 2.4 and 2.6 kernels.

BUILDING:
In most cases just run make and relax. For some linux distributions, however, 
matters should be fine tuned in build_curl.sh and Makefile (libidn issues, etc). 
Sorry. Please, fill you free to contact us for assistance.
Tarball of curl should be fetched by wget from the curl web-site. 
If your computer does not have Internet connection, bring the package yourself 
and put it inside to the distribution to the directory "packages".
We are normally building it at Debian. When libcurl of curl-loader have building 
issues, correct them in the Makefile and build_curl.sh. To build with optimization, 
please, follow the instructions in Makefile and build_curl.sh

CONFIGURATION:
./curl_loader -h output is your friend. Some examples of configuration are 
suggested in the files, located in "configs" directory.

ENVIRONMENT: ATTENTION !!! IMPORTANT !!!
Running hundreds and thousands of clients, please do not forget:
    - to increase limit of descriptors (sockets) by running e.g. 
    #ulimit -n 10000;
    - optionally, to set reuse of sockets in time-wait state: by setting 
    #echo 1 > /proc/sys/net/ipv4/tcp_tw_recycle and/or  
    #echo 1 > /proc/sys/net/ipv4/tcp_tw_reuse;

PERFORMANCE ISSUES:
A limit of 1000 clients per batch (due to select) may be worked around by 
a script, which runs several instances of curl_loader, each with 1000 clients.
Running several batches with threads (option -t), each with 1000 clients is 
another valid option, however, may be less stable - try it.
Some future release will hopefully incorporate libcurl HYPER API, using 
curl_multi_socket() approach and epoll API support by libevent as in
http://curl.haxx.se/lxr/source/hiper/hipev.c


MODES:
The default mode is "storming", where all clients of a batch are starting 
together. They are expected to finish their job within a certain timeout.
After the timeout they are either completed fetching url, or are cutted
and disconnected and a new cycle begins.
Another mode is a so-called "smooth" (-m2 command line), where each 
client spends as much time as wishes and starts another url or another 
cycle only after completing the previous url.
A combination of the both modes (two separate instances of the program)
can provide somehow realistic behavior with some "smooth" load plus
"storming" bursts of requests.

LICENSE:
Actually it is GPL2 due to the code from iprouted2. However, if somebody
fills uncomfortable with this license, we can substitute the code of
ip_secondary.c to calls to command "ip", and release it under BSD-license,
and/or make it configurable.

TERMINOLOGY:
--- What is the batch?
Batch is a group of clients with the same characteristics and 
loading behavior. Configuration file has one or more batches.
--- What means UAS?
UAS - user activity simulation - fetching url, sleeping, another url -sleeping
cycles, simulating actual user activity.

COMMAND-LINE AND CONFIG FILE
Usage: run as a root user:
#./curl-loader -f <configuration filename> [other options]

Possible options are:
-c[onnection establishment timeout, seconds]
-f[ilename of configuration to run (batches of clients)]
-l[ogfile rewind after this number of cycles]
-o[utput to stdout bodies of downloaded files - attn!- bulky]
-r[euse established connections, don't run close-open cycles]
-s[tderr printout of client messages instead of to logfile - attn!- bulky]
-t[hreads enable - enables threads, each runs a batch of clients]
-v[erbose output to the logfiles; includes info about headers sent/received]
-u[rl logging - enables logging of url names to all client outputs]

Note, that running with threads (-t) may be less stable,
whereas without this option runs only the first batch of clients specified.
Thus, running several client batches without threads requires some script with
several curl-loader processes.

Configuration file should possess at least one client batch defined
with the following params in each batch:

----------------------------------------------------------------------------
########### GENERAL SECTION ################################
BATCH_NAME= bulk_batch     # The name of the batch. Logfile - bulk_batch.log
CLIENTS_NUM=3              # Number of clients in the batch
INTERFACE = eth0           # Name of the network interface from which to load 
NETMASK=20                 # Netmask in CIDR-notation (number of bits with 1)
IP_ADDR_MIN= 192.168.1.1   # The client addresses starting address
IP_ADDR_MAX= 192.168.5.255 # Redundant, for self-control
CYCLES_NUM= 100            # Number of loading cycles to run, 0 -forever

########### LOGIN SECTION ##################################
LOGIN=n           # If 'y' or 'Y', login enabled, all other tags of the 
                  # section to be filled. If 'n' or 'N' - comment out others
#LOGIN_USERNAME=  # Username string
#LOGIN_PASSWORD=  # Password string
#LOGIN_REQ_TYPE=  # Use string either GET+POST or POST
#LOGIN_POST_STR=  # POST string matrix. See below:
#
# To generate multiple unique users with unique passwords, use the string like
# "username=%s%d&password=%s%d". First '%s' will be substituted by the 
# value of LOGIN_USERNAME tag and '%d' by the client number. Second '%s' will
# be substituted by LOGIN_PASSWORD tag value and second '%d' by the same client
# number. For example, if LOGIN_USERNAME=robert, LOGIN_PASSWORD=stam
# and LOGIN_POST_STR "username=%s%d&password=%s%d", the final POST string, 
# used for the client number 1, will be  "username=robert1&password=stam1".
# In this case LOGIN_USERNAME and LOGIN_PASSWORD strings are used just 
# as base-words for generating unique user credentials by appending an number.
#
# To use the username and password 'as as', just provide LOGIN_POST_STR without 
# %d symbols, e.g. "user=%s&secret=%s". Thus, all clients will have the same
# POST credentials with the string looking like "user=robert&secret=stam".
#
# Note, that the words like 'username', 'user', 'password', 'secret', etc are 
# those fields, that login users are required to fill in their POST page.

#LOGIN_URL=                 # A valid http or https url to be used for login
#LOGIN_URL_MAX_TIME=        # Maximum batch time in seconds to login
#LOGIN_URL_INTERLEAVE_TIME= # Time in seconds to sleep after login
#LOGIN_CYCLING=             # If 'y' login should be run in cycles, and not 
                            # just done only once

########### UAS SECTION ####################################
UAS=y            # If 'y' or 'Y', login enabled, and other lines of the section 
                 # to be filled
UAS_URLS_NUM = 2 # Number of urls

UAS_URL=ftp://anonymous:stam@localhost/curl-7.16.0.tar.gz # Rather large file
UAS_URL_MAX_TIME = 20        # Maximum batch time in seconds to fetch the url
UAS_URL_INTERLEAVE_TIME = 0 # Time in seconds to sleep after fetching the url

UAS_URL= http://localhost/apache2-default/index.html
UAS_URL_MAX_TIME = 4        # Maximum batch time in seconds to fetch the url
UAS_URL_INTERLEAVE_TIME = 0 # Time in seconds to sleep after fetching the url

# You may add any number of urls providing 3-tags for each url as above,
# but do not forget to update the UAS_URLS_NUM.

########### LOGOFF SECTION #################################
LOGOFF=n                 # If 'y' or 'Y', login enabled, and other tags of the 
                         # section to be filled. If 'n' or 'N' - comment out others
#LOGOFF_REQ_TYPE=        # Use strings to be GET, GET+POST, or POST
#LOGOFF_POST_STR=        # String to be used for logoff, like "op=logoff" 
#LOGOFF_URL=             # A valid http or https url to be used for logoff
#LOGOFF_URL_MAX_TIME=    # Maximum batch time in seconds to logoff
#LOGOFF_URL_INTERLEAVE_TIME= # Time in seconds to sleep after logoff
#LOGOFF_CYCLING=         # If 'y' login should be run in cycles, and not just 
                         # done only once
--------------------------------------------------------------------------------

Worth to mention, that each batch configuration should contain all tags from
the section GENERAL as well as LOGIN, UAS and LOGOFF section tags. When 
LOGIN, UAS or LOGOFF is set as 'y' (yes), all tags for that section should 
appear (uncommented) and to be set to some valid values (N/A string to be used 
not to define LOGIN_POST_STR and LOGOFF_POST_STR tags, when POST 
is not applicable). In the case, that LOGIN, UAS or LOGOFF section tag is 
disabled by setting 'n' (no) value, thus, all the tags of the disabled section 
should not appear or just to be simply commented out by '#'.

For more examples, please, look at configs directory.

Note, that currently there is a limit of 1000 sockets per batch of clients.
Running thousands and more clients, please do not forget the options:
- to increase limit of open desriptors in shell by running e.g. "#ulimit -n 10000":
- to increase total limit of  open descriptors in system somewhere in /proc
- to consider reusing sockets in time-wait state: by "#echo 1 > 
  /proc/sys/net/ipv4/tcp_tw_recycle"
- and/or  "#echo 1 > /proc/sys/net/ipv4/tcp_tw_reuse"

There are two login modes supported. GET+POST and POST-only. 
There are three logoff modes supported as GET-only, GET+POST and POST-only.
HTTP cookies are enabled in curl-loader by default.

To generate FTP/FTPS load, please, use UAS section and pass user credentials
via ftp-url according to the RFC 1738), like:
ftp://username:password@hostname:port/etc-str
