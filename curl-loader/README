    curl-loader
    Robert Iakobashvili, Ashdod, Israel, coroberti@gmail.com
    Michael Moser, Modiin, Israel, moser.michael@gmail.com

ABOUT:
    Provides application load using libcurl/openssl stacks, simulating behaviour
of thousands and tens of thousands clients, each with its own source IP-address.
    This version simulates HTTP/HTTPS and FTP/FTPS (experimental) clients. 
Activities of each virtual client are logged to file: resolving, connection
establishment, sending of requests, receiving responses, headers and data 
received/sent, errors from network, SSL and application (HTTP, FTP) levels. 
The tool can be easily extended to generate telnet, tftp, ldap, etc other 
application load, supported by the great libcurl library.
    Virtual clients are grouped to so-called batches of clients, performing
the same sort of activities. Configurable activities for the simulated clients are:
- authentication login;
- user activity simulation by fetching several urls and timeouts in between;
- logoff.

LICENSE:
Actually it is GPL2 due to the code from iprouted2. However, if somebody
fills uncomfortable with this license, we can substitute the code of
ip_secondary.c to calls to command "ip", and release it under BSD-license,
and/or make it configurable.

TERMINOLOGY:
--- What is the batch?
Batch is a group of clients with the same characteristics and 
loading behavior. Configuration file has one or more batches.
--- What means UAS?
UAS - user activity simulation - fetching url, sleeping, another url -sleeping
cycles, simulating actual user activity.


SUCCESSFULLY USED:

1. To simulate HTTP/S load of thousands of clients against authentication 
   gateway for testing of the gateway performance in various scenarios.

    curl-loader supplied HTTP/S client load against Apache web-server with the 
    gateway in the middle, where the gateway made a browser hijacking and HTTP- 
    redirection of the curl-clients to the HTTPS url at the gateway's own 
    web-server. HTTPS page of the web-server provided a POST form to the user
    with username and password for the client/user authentication against
    an external AAA (RADIUS) server. If the authentication was OK, user (a libcurl
    virtual client object) was allowed to enter the Internet and to perform some
    sort of simulated by curl-loader network activity, namely, fetching urls and 
    sleeping in between them. After enjoying Internet, user was coming to logoff.
    
2. To test web-server pages, authenticating tens and hundred thousand of
    clients, where each client comes to a HTTPS url using GET method and is
    redirected by the web-server to another url, providing authentication POST 
    form with username and password. After successful authentication of a client
    the web-server was setting to the client server-cookies. Client activities were 
    further simulated by fetching urls and sleeping in between. Clients were 
    doing logoff using GET-method to the web-server logoff-url, where the cookies
    were used by the web-server to verify clients identity.

3. To generate Gbps traffic from thousands of TCP/HTTP clients and to test the 
    impact of thousands of firewalling and NAT iptables/ipset rules and 
    hundreds of the rules being added/deleted each second at performance of a 
    gateway device.

    curl-loader provided client load against Apache web-server fetching a 
    url with a gigabyte file, thus, creating a permanent heavy-load 
    traffic, containing thousands of tcp-streams at the gateway in the middle.

MAY BE USED:
1. To create testing load for various HTTP/HTTPS/FTP/FTPS/LDAP, etc devices, 
    where libcurl supports various variants and flavors of the protocols;
2. For testing of HTTP/HTTPS, FTP/FTPS based applications, application servers;
3. For etc, etc, etc applications.

LOGIN/LOGOFF SUPPORT:
There are 3 login and logoff modes supported. GET+POST (response to GET provides
a post-form to be filled and posted by the next POST), POST-only and GET-only.

AUTHENTICATION SUPPORT:
The loader supports HTTP Authentication and Proxy Authentication.
Authentication methods supported are Basic, Digest (RFC2617) and NTLM.
When responded 401 or 407, libcurl will choose the most safe method
from those, supported by the server.
To support GSS Web-Authentication, add in Makefile building of libcurl
against appropriate GSS library, see libcurl pages for detailed instructions.

COOKIES SUPPORT:
HTTP cookies are enabled in curl-loader by default.

FTP/FTPS LOAD (experimental):
To generate FTP/FTPS load, please, use UAS section and pass user credentials
via ftp-url according to the RFC 1738), like:
ftp://username:password@hostname:port/etc-str
Look at conf-examples/ftp.conf

OS SUPPORT:
Supposed to work on linux 2.4 and 2.6 kernels.

BUILDING:
In most cases just run make and relax. For some linux distributions, however, 
matters should be fine tuned in Makefile (libidn issues, etc). 

Building requirements include:
1. openssl binaries;
2. openssl development package with include files (on debian package libssl-dev);
3. ncurses development package to run 'make menuconfig' with dialog GUI.

Adjust Makefile variables to point to the openssl headers and 
libraries. If you want to specify an openssl development directory with 
include files (e.g. crypto.h), export environment variable OPENSSLDIR with 
the value of that directory.

Another known issue is linidn.so, which means, that some linux distributions 
do have some libidn.so.11, but not libidn.so. Resolve it by creating a softlink.

Tarball of curl is included to the current release. When libcurl or curl-loader 
have building issues, correct them in the Makefile. 

By default, we build both libcurl and curl-loader without optimization and with
debugging. To build with optimization and without debugging, please, run:
make cleanall 
make optimize=1 debug=0
If still any building issues, please, fill you free to contact us for assistance.


PERFORMANCE ISSUES:
There is no more a limit of 1000 clients per batch due to select FD_SETSIZE,
so you can try 2000 and may be more number of clients from the single thread
(select). Please, care about available sockets and limits. System call select () 
does not scale well with a big number of sockets, therefore, you can try a 
script, which runs several instances of curl_loader, each with 1000-2000 
clients.

Running several batches with threads (option -t), each with 1000-2000 clients is 
another valid option, however, may be less stable - try it.

Some future release will hopefully incorporate libcurl HYPER API, using 
curl_multi_socket() approach and epoll API support by libevent as in
http://curl.haxx.se/lxr/source/hiper/hipev.c
Read also HOWTOS-BIG-LOAD.


MODES:
One of the modes is storming mode (-m1 command line), where all clients 
of a batch are starting together. They are expected to finish their job within 
a certain timeout. After the timeout they are either completed fetching url, 
or are cutted and disconnected and a new cycle begins. 

Another mode is a so-called "smooth" (the default mode or -m2 command line), 
where each client spends as much time as wishes and starts another url or 
another cycle only after completing the previous url. When a client loading is
terminated due to some reason, e.g. connection timeout, the default behavior
is to schedule loading for this client at the next cycle. If -e option is passed to
command line, the client will not be re-scheduled any more, which is usefull
to get indication of errors by monitoring drop in number of active clients. Look
in logfile for errors, and when connection timeout error appears, adjust the
connection timeout using -c command line option. Note, that the smooth mode
is suitable for login-logoff cycles of load.

When the first operation is login, storming mode may require large 10-20-30 
sec time for all clients to accomplish. The indication of that may be 
"empty reply" ERROR from server in log file. Thus, smooth mode, where 
all clients are proceding independently, may be worth to consider. Storming
mode is better to use, when login operation is a single one and not in cycles, 
or when the tool is used just as a traffic generator. From another side
errors in storming mode are the good indications of the server not being 
able to coop with the burst of login requests, whereas smothing mode has a
somehow adaptive character to the server responses rate.

A combination of the both modes (two separate instances of the program)
can provide somehow realistic behavior with some "smooth" load plus
"storming" bursts of requests.

Hyper-mode (option -m3) is currently "under construction".


SMOOTH MODE CLIENTS_INITIAL_INC TAG:
Tag  CLIENTS_INITIAL_INC in batch configuration file serves in gradual increase 
of clients number at the loading initial phase. Use tag CLIENTS_INITIAL_INC in 
GENERAL section to specify the number of loading clients to be added each second 
till the total clients number reaches the number, specified by CLIENTS_NUM tag.

CAPS CONSIDERATIONS
When number of clients is defined by CLIENTS_NUM tag, the number of
CAPS (call attempts per seconds) is derived from the clients number and 
load duration for each cycle comprising from:
- login time with possible redirections and sleeping after login interval;
- uas time for each url with possible redirections, intervals betwee urls and 
  after uas interval;
- logoff time with possible redirections and sleeping after logoff interval;

All these actions and time intervals are configurable in batch file, whereas
url retrival time is also server and network dependent and not always easy 
to predict. The result is that number of clients/requests is a known parameter,
and number of CAPS is something to be estimated from the time of test and
number of requests.


COMMAND-LINE OPTIONS
Usage: run as a root user:
#./curl-loader -f <configuration filename> [other options]

Possible options are:
-c[onnection establishment timeout, seconds]
-e[rror drop client (smooth mode). Client on error doesn't attempt loading any mode]
-i[ntermediate statistics time interval (default 2 seconds)]
-f[ilename of configuration to run (batches of clients)]
-l[ogfile max size in MB (default 1024). On the size reached, file pointer rewinded]
-m[ode of loading, 1 - storming, 2 - smooth (default)]
-o[utput to stdout bodies of downloaded files - attn!- bulky]
-r[euse connections disabled. Close connections and re-open them. Try with and without]
-s[tderr printout of client messages instead of to logfile - attn!- bulky]
-t[hreads enable - enables threads, each runs a batch of clients]
-v[erbose output to the logfiles; includes info about headers sent/received]
-u[rl logging - logs url names to logfile, when -v verbose option is used]

For the rare cases, when several batches are specified in the same config file,
note, please, that curl-loader without -t this option runs only the first batch of 
clients specified.
Thus, running several client batches without threads requires some script with
several curl-loader processes.

Connection Reuse Disable Option (-r):
The default behavior of curl-loader after HTTP response is to re-use the 
tcp-connection for the next request. If you are specifying -r command-line 
option, the TCP connection will be closed and re-opened for the next request. 
Whether it is appropriate for you to work with -r option or without, it  depends
 on your server support of Keep-Alive and the purpose of your testing.
Try with and without -r and see, what you get.

Connection reuse (just the default, without -r option) has advantages due to the 
decreased consumption of opened descriptors (sockets) and ports.


CONFIGURATION FILE
To run your load, you need to create your configuration file to be passed to
curl-loader by -f option, e.g.
#curl-loader -f ./conf-user/user_batch.conf
For more examples, please, look at the files in "conf-examples" directory.
You may copy an example file and edit it by using HOWTOS-CONFIG-FILE.

You may start with running "make menuconfig" on your system, which requires
ncurses development package on your system.
The dialog window will guide you and create your configuration file in 
conf-user directory. The current limitation of the menu-guided configuration, is
that enables to create a single UAS URL.
Just copy your batch file from the conf-user directory  to some other place,
and  edit it by adding as much url tag series (below) as you need, but don't
forget to update UAS_URLS_NUM accordingly.
UAS_URL=
UAS_URL_USERNAME=
UAS_URL_PASSWORD=
UAS_URL_MAX_TIME =
UAS_URL_INTERLEAVE_TIME =

For more details you may look at HOWTOS-CONFIG-FILE

ENVIRONMENT: ATTENTION !!! IMPORTANT !!!
Running hundreds and thousands of clients, please do not forget:
    - to increase limit of descriptors (sockets) by running e.g. 
      #ulimit -n 10000;
    - optionally, to set reuse of sockets in time-wait state: by setting 
      #echo 1 > /proc/sys/net/ipv4/tcp_tw_recycle and/or  
      #echo 1 > /proc/sys/net/ipv4/tcp_tw_reuse;
In some cases you may need to increase the system limits for open
descriptors (sockets).

LOGFILE:
The semantics of logfile output, using command line options -v (verbous) and -u 
(url print):
"Cycle number", "Client number (ip-address)" - some information string, e.g.:

4 39 (192.168.0.39)  :== Info:   Trying 10.30.6.42... : eff-url: http://10.30.6.42:8888/server/Admin/ServiceList.do, url:

Which meas: cycle: 4, client number 39 with ipv4 address (192.168.0.39), 
status of the message is Info, eff-url - is the url, used right now, "url:" is 
empty, which means, that it is the same as effective.

Effective url may be a result of redirection and, thus, "url:" 
(target url, specified in batch configuration file) will be printed as well.


STATISTICS:
Currently HTTP/HTTPS statistics includes the following counters:
   - requests num;
   - responses success num;
   - 3xx redirects num;
   - client 4xx errors num;
   - server 5xx errors num;
   - other errors num, like resolving, tcp-connect, server closing or 
     empty responses number;
   - average application server delay (msec), estimated as the time between 
     HTTP request and HTTP response without taking into the account network
     latency (RTT);
   - average application server delay for 2xx (success) HTTP-responses, as above,
     but only for 2xx responses. The motivation for that is that 3xx redirections
     and 5xx server errors/rejects may not necessarily provide a true indication
     of a testing server working functionality.
   - throughput out (batch average);
   - throughput in (batch average);

The statistics goes to the screen (both the interval and the current summary 
statistics for the load) as well as to the file with name $batch_name.txt
When the load completes or when the user presses CTRL-C (sometimes some clients
may stall), the final load report is printed at the console as well as to the statistics
file. 
Some strings from the file:
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Run-Time,Appl,Clients,Req,2xx,3xx,4xx,5xx,Err,Delay,Delay-2xx,Thr-In,Thr-Out
2, HTTP/FTP, 100, 155, 0, 96, 0, 0, 1154, 1154, 2108414, 15538
2, HTTPS/FTPS, 100, 0, 0, 0, 0, 0, 0, 0, 0, 0
4, HTTP/FTP, 100, 75, 32, 69, 0, 0, 1267, 1559, 1634656, 8181
4, HTTPS/FTPS, 100, 0, 0, 0, 0, 0, 0, 0, 0, 0

Cutted here

36, HTTP/FTP, 39, 98, 35, 58, 0, 0, 869, 851, 1339168, 11392
36, HTTPS/FTPS, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0
38, HTTP/FTP, 3, 91, 44, 62, 0, 0, 530, 587, 1353899, 10136
38, HTTPS/FTPS, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0
*, *, *, *, *, *, *, *, *, *, *, *
Run-Time,Appl,Clients,Req,2xx,3xx,4xx,5xx,Err,Delay,Delay-2xx,Thr-In,Thr-Out
38, HTTP/FTP, 0, 2050, 643, 1407, 0, 213, 725, 812, 1610688, 11706
38, HTTPS/FTPS, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
The bottom strings after asterisks are for final averages.

At the same time a clients dump file with name $batch_name.ctx is generated
to provide detailed statistics about each client state and statistics counters.

One string from the file
1 (192.168.0.1) ,cycles:124,cstate:1,b-in:22722029,b-out:174605,req:745,2xx:497,3xx:248,4xx:0,5xx:0,err:0
where
1 (192.168.0.1)- is the index of the client and its ip-address;
cycles- number of loading cycles done;
cstate - is the number of the client state (-1 - error, 0 - init, 1- login, 2- uas, 3-logoff, 4-final-ok);
b-in - bytes passed in;
b-out - bytes passed out;
req- number of requests done;
2xx, 3xx, 4xx, 5xx - number of responses Nxx received;
err - number of libcurl errors at the resolving, TCP/IP and TLS/SSL levels;


ERROR CONDITIONS OF A VIRTUAL CLIENT:
\The following conditions are considered as errors:
- error at the level of libcurl, which includes resolving, TCP/IP and, when applicable,
  TLS/SSL errors;
- all HTTP 5xx server errors;
- most of HTTP 4xx client errors, excluding are 401 and 407 authentication responses
  not considered as errors;
When the above error conditions occur, a virtual client is marked as being 
in the error state.
By default we "recover" such client by scheduling it to the next loading cycle, 
starting from the first operation of the cycle. You may use command line option
-e to change the default behavior to another, so that clients once arriving at 
error state will not be scheduled for load any more. 


HOWTOS-BIG-LOAD
The file contains some useful tips.

LIMITATIONS:
See the TODO file for some of them.
